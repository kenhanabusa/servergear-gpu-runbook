#!/usr/bin/env bash
set -euo pipefail
. /usr/local/lib/sg-runbook/lib/common.sh
require_root
ensure_log_dir

OUT="$RB_LOG_DIR/install_slurm_single_$(_rb_now).log"
exec > >(tee -a "$OUT") 2>&1

usage() {
  cat >&2 <<'USAGE'
Usage:
  sg-install-slurm-single [--cluster <name>] [--partition <name>] [--no-reset-state]

Defaults:
  --cluster   mycluster
  --partition debug
  (reset-state enabled by default to avoid CLUSTER NAME MISMATCH)

This script:
  - installs munge + slurm packages
  - writes /etc/slurm/slurm.conf and /etc/slurm/gres.conf
  - forces -f /etc/slurm/slurm.conf via /etc/default/slurmctld and /etc/default/slurmd
  - starts munge, slurmctld, slurmd
USAGE
  exit 2
}

CLUSTER="mycluster"
PART="debug"
RESET_STATE="yes"

while [[ $# -gt 0 ]]; do
  case "$1" in
    --cluster) CLUSTER="${2:-}"; shift 2 ;;
    --partition) PART="${2:-}"; shift 2 ;;
    --no-reset-state) RESET_STATE="no"; shift ;;
    -h|--help) usage ;;
    *) die "unknown arg: $1" ;;
  esac
done

HOST="$(hostname -s)"
CPUS="$(nproc)"
MEMMB="$(free -m | awk '/^Mem:/ {print $2}')"
# leave 1024MB headroom
if [[ "$MEMMB" -gt 4096 ]]; then MEMMB="$((MEMMB-1024))"; fi

GPUCOUNT="0"
if have_cmd nvidia-smi; then
  GPUCOUNT="$(nvidia-smi -L 2>/dev/null | wc -l || echo 0)"
fi

log "==== sg-install-slurm-single start ===="
log "ClusterName=$CLUSTER Host=$HOST CPUs=$CPUS RealMemory(MB)=$MEMMB GPUs=$GPUCOUNT"

export DEBIAN_FRONTEND=noninteractive

apt-get update
# Ubuntu noble provides these packages
apt-get install -y munge slurmctld slurmd slurm-client slurm-wlm-basic-plugins

# stop auto-started services while we configure
systemctl stop slurmctld slurmd munge 2>/dev/null || true

# ensure users exist
id -u munge >/dev/null 2>&1 || useradd --system --home /var/lib/munge --shell /usr/sbin/nologin munge
id -u slurm >/dev/null 2>&1 || useradd --system --home /var/lib/slurm --shell /usr/sbin/nologin slurm

# munge key
install -d -m 0700 -o munge -g munge /etc/munge
if [[ ! -f /etc/munge/munge.key ]]; then
  log "Generating /etc/munge/munge.key"
  dd if=/dev/urandom bs=1 count=1024 of=/etc/munge/munge.key status=none
  chown munge:munge /etc/munge/munge.key
  chmod 0400 /etc/munge/munge.key
else
  log "Munge key exists"
  chown munge:munge /etc/munge/munge.key
  chmod 0400 /etc/munge/munge.key
fi

# slurm dirs
install -d -m 0755 -o slurm -g slurm /var/spool/slurmctld
install -d -m 0755 -o slurm -g slurm /var/spool/slurmd
install -d -m 0755 -o slurm -g slurm /var/log/slurm
install -d -m 0755 -o root  -g root  /etc/slurm

if [[ "$RESET_STATE" == "yes" ]]; then
  log "Resetting slurmctld state dir to avoid CLUSTER NAME MISMATCH"
  rm -rf /var/spool/slurmctld/*
fi

# slurm.conf
cat > /etc/slurm/slurm.conf <<CONF
# Generated by sg-install-slurm-single on $(date -Is)
ClusterName=$CLUSTER
SlurmctldHost=$HOST
SlurmUser=slurm

AuthType=auth/munge
CryptoType=crypto/munge

StateSaveLocation=/var/spool/slurmctld
SlurmdSpoolDir=/var/spool/slurmd

SlurmctldPort=6817
SlurmdPort=6818

SwitchType=switch/none
MpiDefault=none

ProctrackType=proctrack/cgroup
TaskPlugin=task/cgroup

ReturnToService=2
SlurmctldTimeout=300
SlurmdTimeout=300

SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_Core

SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdLogFile=/var/log/slurm/slurmd.log

AccountingStorageType=accounting_storage/none
JobCompType=jobcomp/none

GresTypes=gpu

NodeName=$HOST CPUs=$CPUS RealMemory=$MEMMB Gres=gpu:$GPUCOUNT State=UNKNOWN
PartitionName=$PART Nodes=$HOST Default=YES MaxTime=INFINITE State=UP
CONF
chmod 0644 /etc/slurm/slurm.conf

# gres.conf
: > /etc/slurm/gres.conf
if [[ "$GPUCOUNT" -gt 0 ]]; then
  for i in $(seq 0 $((GPUCOUNT-1))); do
    echo "Name=gpu File=/dev/nvidia${i}" >> /etc/slurm/gres.conf
  done
else
  # keep file; node still works without GPU scheduling
  echo "# No GPUs detected at install time" >> /etc/slurm/gres.conf
fi
chmod 0644 /etc/slurm/gres.conf

# force -f /etc/slurm/slurm.conf (avoid configless/DNS SRV)
set_default_opt() {
  local file="$1" key="$2" val="$3"
  if [[ -f "$file" ]]; then
    if grep -qE "^${key}=" "$file"; then
      sed -i -E "s|^${key}=.*$|${key}=\"${val}\"|" "$file"
    else
      echo "${key}=\"${val}\"" >> "$file"
    fi
  else
    echo "${key}=\"${val}\"" > "$file"
  fi
}
set_default_opt /etc/default/slurmctld SLURMCTLD_OPTIONS "-f /etc/slurm/slurm.conf"
set_default_opt /etc/default/slurmd   SLURMD_OPTIONS   "-f /etc/slurm/slurm.conf"

# start services
systemctl enable --now munge
systemctl enable --now slurmctld
systemctl enable --now slurmd

sleep 2

# verify minimal
if ! systemctl is-active --quiet munge; then
  journalctl -u munge -n 200 --no-pager || true
  die "munge not active"
fi
if ! systemctl is-active --quiet slurmctld; then
  journalctl -u slurmctld -n 200 --no-pager || true
  die "slurmctld not active"
fi
if ! systemctl is-active --quiet slurmd; then
  journalctl -u slurmd -n 200 --no-pager || true
  die "slurmd not active"
fi

scontrol ping || true
sinfo || true

# If cluster mismatch occurs, it will be in slurmctld log/journal.
if journalctl -u slurmctld -n 200 --no-pager | grep -q "CLUSTER NAME MISMATCH"; then
  die "Detected CLUSTER NAME MISMATCH. Try re-run with reset-state (default) or wipe /var/spool/slurmctld/*"
fi

log "==== sg-install-slurm-single done ===="
log "Log: $OUT"
